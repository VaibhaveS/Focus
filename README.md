# Online meeting analyser for interviews using image processing and NLP
<a name="overview">

#### Overview

We provide an **online interview analyser** which can extract information related to online interviews from the **video and audio recording**. The system is designed to  analyse the emotions of the interviewees using image processing and deep learning techniques along with analysis on the audio of the interview using NLP and Machine learning techniques. Our system provides a detailed analysis of the interview. Companies can use the results from the system to judge the candidate.

 
<a name="installation" />

### Installation

1. Clone this repository

```sh
$ git clone https://github.com/VaibhaveS/Focus.git
```

2. Change directory to that folder

```sh
$ cd Focus
```
  
3. Run the jupyter notebooks 
  
```sh
$ open them manually or use py -m Audio.ipynb and Process.ipynb
```
 
4. Enable Google cloud Speech-to-Text API 
 
 ```sh 
 https://console.cloud.google.com/
 ```

5. Open Homepage.html in the browser
 
<a name="features">

#### Features

- [x] Average response time of the interviewee
- [x] Bar chart signifying the count of each emotion
- [x] Number of active speakers (in a normal interview setting it should be two, but may vary)
- [x] Number of questions asked
- [x] Percentage of non-trivial questions
- [x] Percentage of interesting questions
 
<p align="center">
  <img src="https://github.com/VaibhaveS/Focus/blob/main/LOGO5.gif" style="margin:auto">
</p>
